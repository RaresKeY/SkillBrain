{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11 – Hashing Techniques and Optimized Data Structures in Python\n",
    "\n",
    "_Exercise notebook (without solutions)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Indexing PDF books with hashing\n",
    "\n",
    "Create a system that:\n",
    "- Iterates through multiple PDF files\n",
    "- Computes the SHA-256 hash of each file\n",
    "- Stores the results in a dictionary\n",
    "- Identifies duplicate files based on their hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0fc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58bd9a6814d01231253ed537c8308c9d323534172f0c499ab1e640e1bcc0c293 [DUPLIC] ['book_alpha_copy.pdf', 'book_alpha.pdf']\n",
      "8c17eac149c61478980d1b956ff8fd3b0970f32762fbc64578f7ec81d43fddf6 [DUPLIC] ['book_beta_copy.pdf', 'book_beta.pdf']\n",
      "5c2e490ef930af42dac33db0e4abf9f7b9c0fd5a75da1245eb2a787417f11d29 [UNIQUE] ['book_gamma.pdf']\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(\"ex1_pdfs\")\n",
    "\n",
    "def compute_hash(filepath):\n",
    "    sha = hashlib.sha256()\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        while chunk := f.read(4096):\n",
    "            sha.update(chunk)\n",
    "    return sha.hexdigest()\n",
    "\n",
    "hashes = dict()\n",
    "duplicates = []\n",
    "\n",
    "for file in folder_path.iterdir():\n",
    "    if file.is_file() and file.suffix == '.pdf':\n",
    "        hashes.setdefault(compute_hash(file), []).append(file.name)\n",
    "\n",
    "for k, v in hashes.items():\n",
    "    print(k, end='')\n",
    "    print(' [DUPLIC]' if len(v) > 1 else ' [UNIQUE]', end=' ')\n",
    "    if len(v) > 1:\n",
    "        duplicates.append({k: v})\n",
    "    print(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0d44a",
   "metadata": {},
   "source": [
    "## Exercise 2 – Finding duplicates in 10,000 names\n",
    "\n",
    "Generate or load a large list of names.\n",
    "- Use a `set` for fast duplicate detection\n",
    "- Display the duplicate names\n",
    "- Measure execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f18a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total names: 10000\n",
      "Unique names: 397\n",
      "Duplicate names found: 397\n",
      "Execution time: 0.002777 seconds\n",
      "Sample duplicates: ['Alexander Anderson', 'Alexander Brown', 'Alexander Davis', 'Alexander Garcia']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "def generate_names(total=10_000, unique_pool=2_000, seed=42):\n",
    "    random.seed(seed)\n",
    "    first_names = [\n",
    "        \"Liam\", \"Noah\", \"Oliver\", \"Elijah\", \"James\", \"William\", \"Benjamin\", \"Lucas\", \"Henry\", \"Alexander\",\n",
    "        \"Olivia\", \"Emma\", \"Charlotte\", \"Amelia\", \"Sophia\", \"Isabella\", \"Ava\", \"Mia\", \"Evelyn\", \"Luna\"\n",
    "    ]\n",
    "    last_names = [\n",
    "        \"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\",\n",
    "        \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\", \"Anderson\", \"Thomas\", \"Taylor\", \"Moore\", \"Jackson\", \"Martin\"\n",
    "    ]\n",
    "\n",
    "    pool = [f\"{random.choice(first_names)} {random.choice(last_names)}\" for _ in range(unique_pool)]\n",
    "    return [random.choice(pool) for _ in range(total)]\n",
    "\n",
    "names = generate_names(total=10_000, unique_pool=2_000)\n",
    "\n",
    "start = time.perf_counter()\n",
    "seen = set()\n",
    "duplicates = set()\n",
    "\n",
    "for name in names:\n",
    "    if name in seen:\n",
    "        duplicates.add(name)\n",
    "    else:\n",
    "        seen.add(name)\n",
    "\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"Total names: {len(names)}\")\n",
    "print(f\"Unique names: {len(seen)}\")\n",
    "print(f\"Duplicate names found: {len(duplicates)}\")\n",
    "print(f\"Execution time: {elapsed:.6f} seconds\")\n",
    "print(\"Sample duplicates:\", sorted(duplicates)[:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70dbc18",
   "metadata": {},
   "source": [
    "## Exercise 3 – Top 5 most frequent words (Counter)\n",
    "\n",
    "Receive a long text.\n",
    "- Normalize the text (lowercase, remove punctuation)\n",
    "- Use `collections.Counter`\n",
    "- Display the top 5 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ee0c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 data\n",
      "6 and\n",
      "5 python\n",
      "3 hashing\n",
      "3 in\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open(\"ex3_text.txt\", 'r', encoding='utf-8') as f:\n",
    "    data = [x.strip('\\n.,;-') for x in f.readlines()]\n",
    "\n",
    "full_data = [y.strip().lower() for x in data for y in x.split(' ')]\n",
    "\n",
    "counts = Counter(full_data)\n",
    "\n",
    "for k, v in counts.most_common(5):\n",
    "    print(v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477db652",
   "metadata": {},
   "source": [
    "## Exercise 4 – Build your own HashMap\n",
    "\n",
    "Manually implement a HashMap structure:\n",
    "- Create a `HashMap` class\n",
    "- Define a hash function\n",
    "- Handle collisions (bucket chaining using lists)\n",
    "- Implement methods: `put`, `get`, `delete`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0943a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple -> 99\n",
      "banana -> 20\n",
      "grape -> None\n",
      "delete banana: True\n",
      "banana -> None\n",
      "delete grape: False\n"
     ]
    }
   ],
   "source": [
    "class HashMap:\n",
    "    def __init__(self, size=10):\n",
    "        self.size = size\n",
    "        self.buckets = [[] for _ in range(size)]\n",
    "\n",
    "    def _hash(self, key):\n",
    "        return hash(key) % self.size\n",
    "\n",
    "    def put(self, key, value):\n",
    "        i = self._hash(key)\n",
    "        bucket = self.buckets[i]\n",
    "\n",
    "        for item in bucket:\n",
    "            if item[0] == key:\n",
    "                item[1] = value\n",
    "                return\n",
    "\n",
    "        bucket.append([key, value])\n",
    "\n",
    "    def get(self, key):\n",
    "        i = self._hash(key)\n",
    "        bucket = self.buckets[i]\n",
    "\n",
    "        for k, v in bucket:\n",
    "            if k == key:\n",
    "                return v\n",
    "\n",
    "        return None\n",
    "\n",
    "    def delete(self, key):\n",
    "        i = self._hash(key)\n",
    "        bucket = self.buckets[i]\n",
    "\n",
    "        for j, item in enumerate(bucket):\n",
    "            if item[0] == key:\n",
    "                del bucket[j]\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "hmap = HashMap(size=5)\n",
    "\n",
    "hmap.put(\"apple\", 10)\n",
    "hmap.put(\"banana\", 20)\n",
    "hmap.put(\"orange\", 30)\n",
    "hmap.put(\"apple\", 99)\n",
    "\n",
    "print(\"apple ->\", hmap.get(\"apple\"))\n",
    "print(\"banana ->\", hmap.get(\"banana\"))\n",
    "print(\"grape ->\", hmap.get(\"grape\"))\n",
    "\n",
    "print(\"delete banana:\", hmap.delete(\"banana\"))\n",
    "print(\"banana ->\", hmap.get(\"banana\"))\n",
    "print(\"delete grape:\", hmap.delete(\"grape\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7873e40d",
   "metadata": {},
   "source": [
    "## Exercise 5 – Auto-complete using prefix hashing\n",
    "\n",
    "Create a simple auto-complete system:\n",
    "- Receive a list of words\n",
    "- Build a hashing-based structure for prefixes\n",
    "- Return all words starting with a given prefix\n",
    "- Optimize for fast lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65daa265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words loaded: 36\n",
      "Total prefixes indexed: 120\n",
      "ap -> ['apple', 'application', 'apply', 'apricot']\n",
      "sta -> ['stack', 'stamina', 'stamp', 'standard', 'start', 'starter', 'state', 'station']\n",
      "py -> ['python', 'pycharm', 'pyramid', 'pytorch']\n",
      "zzz -> []\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "words_path = Path(\"ex5_words.txt\")\n",
    "words = [line.strip().lower() for line in words_path.read_text().splitlines() if line.strip()]\n",
    "\n",
    "prefix_map = dict()\n",
    "\n",
    "for word in words:\n",
    "    for i in range(1, len(word) + 1):\n",
    "        prefix = word[:i]\n",
    "        prefix_map.setdefault(prefix, []).append(word)\n",
    "\n",
    "def autocomplete(prefix):\n",
    "    return prefix_map.get(prefix.lower(), [])\n",
    "\n",
    "print(\"Total words loaded:\", len(words))\n",
    "print(\"Total prefixes indexed:\", len(prefix_map))\n",
    "print(\"ap ->\", autocomplete(\"ap\"))\n",
    "print(\"sta ->\", autocomplete(\"sta\"))\n",
    "print(\"py ->\", autocomplete(\"py\"))\n",
    "print(\"zzz ->\", autocomplete(\"zzz\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
