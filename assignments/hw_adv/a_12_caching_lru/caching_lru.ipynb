{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "64588ead",
      "metadata": {},
      "source": [
        "# Session 12 - Caching, LRU Cache, and Smart Memory Systems\n",
        "\n",
        "_Exercise notebook (with solutions)._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4d175be",
      "metadata": {},
      "source": [
        "## Exercise 1: Manual Cache (Dictionary)\n",
        "\n",
        "- Implement a manual cache using a global/local dictionary.\n",
        "- Write a function `heavy_calculation(x)` that:\n",
        "  - returns from cache if value exists;\n",
        "  - otherwise computes (simulates expensive work), stores, and returns it.\n",
        "- Print different messages for \"from cache\" vs \"new computation\".\n",
        "- Test with repeated calls for the same `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f41021b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[new compute] x=5\n",
            "result(5) = 67\n",
            "[new compute] x=7\n",
            "result(7) = 91\n",
            "[cache hit] x=5\n",
            "result(5) = 67\n",
            "[cache hit] x=7\n",
            "result(7) = 91\n",
            "[new compute] x=9\n",
            "result(9) = 123\n",
            "[cache hit] x=5\n",
            "result(5) = 67\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "manual_cache = {}\n",
        "\n",
        "\n",
        "def heavy_calculation(x: int) -> int:\n",
        "    if x in manual_cache:\n",
        "        print(f\"[cache hit] x={x}\")\n",
        "        return manual_cache[x]\n",
        "\n",
        "    print(f\"[new compute] x={x}\")\n",
        "    time.sleep(0.5)  # simulate expensive work\n",
        "    result = x * x + 42\n",
        "    manual_cache[x] = result\n",
        "    return result\n",
        "\n",
        "\n",
        "for value in [5, 7, 5, 7, 9, 5]:\n",
        "    print(f\"result({value}) = {heavy_calculation(value)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ceae08c",
      "metadata": {},
      "source": [
        "## Exercise 2: LRU Cache with `functools.lru_cache`\n",
        "\n",
        "- Use `@lru_cache(maxsize=3)` on a slow function (for example with `time.sleep`).\n",
        "- Call the function on a value sequence so you can observe:\n",
        "  - cache hits;\n",
        "  - eviction of the least recently used entry once `maxsize` is exceeded.\n",
        "- Show when the function computes vs serves from cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2cc5d2c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[computed] slow_square(1)\n",
            "x= 1 ->  1 [computed]\n",
            "[computed] slow_square(2)\n",
            "x= 2 ->  4 [computed]\n",
            "[computed] slow_square(3)\n",
            "x= 3 ->  9 [computed]\n",
            "x= 1 ->  1 [cache]\n",
            "[computed] slow_square(4)\n",
            "x= 4 -> 16 [computed]\n",
            "[computed] slow_square(2)\n",
            "x= 2 ->  4 [computed]\n",
            "[computed] slow_square(5)\n",
            "x= 5 -> 25 [computed]\n",
            "[computed] slow_square(1)\n",
            "x= 1 ->  1 [computed]\n",
            "cache_info: CacheInfo(hits=1, misses=7, maxsize=3, currsize=3)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=3)\n",
        "def slow_square(x: int) -> int:\n",
        "    print(f\"[computed] slow_square({x})\")\n",
        "    time.sleep(0.3)\n",
        "    return x * x\n",
        "\n",
        "\n",
        "for x in [1, 2, 3, 1, 4, 2, 5, 1]:\n",
        "    before = slow_square.cache_info()\n",
        "    result = slow_square(x)\n",
        "    after = slow_square.cache_info()\n",
        "    served_from_cache = after.hits > before.hits\n",
        "    source = \"cache\" if served_from_cache else \"computed\"\n",
        "    print(f\"x={x:>2} -> {result:>2} [{source}]\")\n",
        "\n",
        "print(\"cache_info:\", slow_square.cache_info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28f8a94",
      "metadata": {},
      "source": [
        "## Exercise 3: Custom LRU Cache (with `OrderedDict`)\n",
        "\n",
        "- Create class `LRUCache(capacity)` that stores key -> value pairs.\n",
        "- Implement methods:\n",
        "  - `get(key)` -> returns value or `-1` if not found; mark key as recently used.\n",
        "  - `set(key, value)` -> insert/update; if capacity exceeded, evict least recently used key.\n",
        "- Write a short test scenario that demonstrates correct eviction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fb08671e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LRUCache(capacity=3, data=[('A', 10), ('B', 20), ('C', 30)])\n",
            "get('A') = 10\n",
            "Evicted: B -> 20\n",
            "LRUCache(capacity=3, data=[('C', 30), ('A', 10), ('D', 40)])\n",
            "get('B') = -1\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class LRUCache:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.capacity = capacity\n",
        "        self.data = OrderedDict()\n",
        "\n",
        "    def get(self, key):\n",
        "        if key not in self.data:\n",
        "            return -1\n",
        "        self.data.move_to_end(key)  # mark as recently used\n",
        "        return self.data[key]\n",
        "\n",
        "    def set(self, key, value):\n",
        "        if key in self.data:\n",
        "            self.data[key] = value\n",
        "            self.data.move_to_end(key)\n",
        "            return\n",
        "\n",
        "        self.data[key] = value\n",
        "        if len(self.data) > self.capacity:\n",
        "            evicted_key, evicted_value = self.data.popitem(last=False)\n",
        "            print(f\"Evicted: {evicted_key} -> {evicted_value}\")\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"LRUCache(capacity={self.capacity}, data={list(self.data.items())})\"\n",
        "\n",
        "\n",
        "cache = LRUCache(capacity=3)\n",
        "cache.set(\"A\", 10)\n",
        "cache.set(\"B\", 20)\n",
        "cache.set(\"C\", 30)\n",
        "print(cache)\n",
        "print(\"get('A') =\", cache.get(\"A\"))  # A becomes most recent\n",
        "cache.set(\"D\", 40)  # should evict B\n",
        "print(cache)\n",
        "print(\"get('B') =\", cache.get(\"B\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5be18b3e",
      "metadata": {},
      "source": [
        "## Exercise 4: Expiring Cache for a Simulated API\n",
        "\n",
        "- Implement `get_price(crypto)` with cache entries expiring after 10 seconds.\n",
        "- Cache should store both value and expiration timestamp.\n",
        "- If entry is valid, return from cache; otherwise recompute and overwrite.\n",
        "- Test with `time.sleep` to observe behavior before and after expiration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bd788812",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[new fetch] BTC -> 66397.47\n",
            "66397.47\n",
            "[cache hit] BTC -> 66397.47\n",
            "66397.47\n",
            "waiting 10.5 seconds for expiration...\n",
            "[new fetch] BTC -> 15981.55\n",
            "15981.55\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "TTL_SECONDS = 10\n",
        "price_cache = {}\n",
        "\n",
        "\n",
        "def get_price(crypto: str) -> float:\n",
        "    now = time.time()\n",
        "    cached = price_cache.get(crypto)\n",
        "\n",
        "    if cached is not None:\n",
        "        value, expires_at = cached\n",
        "        if now < expires_at:\n",
        "            print(f\"[cache hit] {crypto} -> {value:.2f}\")\n",
        "            return value\n",
        "\n",
        "    # simulate API call\n",
        "    value = round(random.uniform(10000, 70000), 2)\n",
        "    expires_at = now + TTL_SECONDS\n",
        "    price_cache[crypto] = (value, expires_at)\n",
        "    print(f\"[new fetch] {crypto} -> {value:.2f}\")\n",
        "    return value\n",
        "\n",
        "\n",
        "print(get_price(\"BTC\"))\n",
        "print(get_price(\"BTC\"))\n",
        "print(\"waiting 10.5 seconds for expiration...\")\n",
        "time.sleep(10.5)\n",
        "print(get_price(\"BTC\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac028c99",
      "metadata": {},
      "source": [
        "## Exercise 5: Custom Cache Decorator\n",
        "\n",
        "- Write decorator `cache_decorator(f)` that stores function results for identical arguments.\n",
        "- In `wrapper(*args)`, check if `args` exist in cache:\n",
        "  - if yes, return cached value and print \"From cache\";\n",
        "  - if not, compute, store, and return.\n",
        "- Apply decorator to a simple function (for example `calculate(x, y)`), then test with repeated calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "695e6905",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computed now\n",
            "11\n",
            "From cache\n",
            "11\n",
            "Computed now\n",
            "28\n",
            "From cache\n",
            "28\n"
          ]
        }
      ],
      "source": [
        "def cache_decorator(func):\n",
        "    cache = {}\n",
        "\n",
        "    def wrapper(*args, **kwargs):\n",
        "        key = (args, tuple(sorted(kwargs.items())))\n",
        "        if key in cache:\n",
        "            print(\"From cache\")\n",
        "            return cache[key]\n",
        "\n",
        "        print(\"Computed now\")\n",
        "        result = func(*args, **kwargs)\n",
        "        cache[key] = result\n",
        "        return result\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "@cache_decorator\n",
        "def calculate(x, y):\n",
        "    return x * y + x - y\n",
        "\n",
        "\n",
        "print(calculate(3, 4))\n",
        "print(calculate(3, 4))\n",
        "print(calculate(10, 2))\n",
        "print(calculate(10, 2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "924fce0a",
      "metadata": {},
      "source": [
        "## Exercise 6: LRU Cache for Temperature Conversion (last 5 results)\n",
        "\n",
        "- Create a temperature conversion function (for example `c_to_f(c)` or `f_to_c(f)`).\n",
        "- Use an LRU mechanism that keeps **the last 5 results**.\n",
        "- Demonstrate that when you exceed 5 entries, the least recently used one is evicted.\n",
        "- You may choose `lru_cache(maxsize=5)` or your own implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0c75f723",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[computed] c_to_f(0)\n",
            " 0C ->  32.0F [computed]\n",
            "[computed] c_to_f(10)\n",
            "10C ->  50.0F [computed]\n",
            "[computed] c_to_f(20)\n",
            "20C ->  68.0F [computed]\n",
            "[computed] c_to_f(30)\n",
            "30C ->  86.0F [computed]\n",
            "[computed] c_to_f(40)\n",
            "40C -> 104.0F [computed]\n",
            "[computed] c_to_f(50)\n",
            "50C -> 122.0F [computed]\n",
            "10C ->  50.0F [cache]\n",
            "[computed] c_to_f(60)\n",
            "60C -> 140.0F [computed]\n",
            "[computed] c_to_f(20)\n",
            "20C ->  68.0F [computed]\n",
            "cache_info: CacheInfo(hits=1, misses=8, maxsize=5, currsize=5)\n"
          ]
        }
      ],
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=5)\n",
        "def c_to_f(celsius: float) -> float:\n",
        "    print(f\"[computed] c_to_f({celsius})\")\n",
        "    return celsius * 9 / 5 + 32\n",
        "\n",
        "\n",
        "for c in [0, 10, 20, 30, 40, 50, 10, 60, 20]:\n",
        "    before = c_to_f.cache_info()\n",
        "    value = c_to_f(c)\n",
        "    after = c_to_f.cache_info()\n",
        "    source = \"cache\" if after.hits > before.hits else \"computed\"\n",
        "    print(f\"{c:>2}C -> {value:>5.1f}F [{source}]\")\n",
        "\n",
        "print(\"cache_info:\", c_to_f.cache_info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ea8ce94",
      "metadata": {},
      "source": [
        "## Exercise 7: Cached Factorials (decorated)\n",
        "\n",
        "- Create function `factorial(n)`.\n",
        "- Apply a cache decorator (standard or custom) so previously computed factorials are reused.\n",
        "- Demonstrate reuse with repeated calls and by printing when computation happens vs cache usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "43cd4428",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[computed] factorial(6)\n",
            "[computed] factorial(5)\n",
            "[computed] factorial(4)\n",
            "[computed] factorial(3)\n",
            "[computed] factorial(2)\n",
            "[computed] factorial(1)\n",
            "factorial(6) = 720 [computed]\n",
            "factorial(6) = 720 [cache]\n",
            "factorial(5) = 120 [cache]\n",
            "[computed] factorial(7)\n",
            "factorial(7) = 5040 [cache]\n",
            "factorial(7) = 5040 [cache]\n",
            "cache_info: CacheInfo(hits=4, misses=7, maxsize=None, currsize=7)\n"
          ]
        }
      ],
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def factorial(n: int) -> int:\n",
        "    if n < 0:\n",
        "        raise ValueError(\"n must be >= 0\")\n",
        "    print(f\"[computed] factorial({n})\")\n",
        "    if n <= 1:\n",
        "        return 1\n",
        "    return n * factorial(n - 1)\n",
        "\n",
        "\n",
        "for n in [6, 6, 5, 7, 7]:\n",
        "    before = factorial.cache_info()\n",
        "    value = factorial(n)\n",
        "    after = factorial.cache_info()\n",
        "    source = \"cache\" if after.hits > before.hits else \"computed\"\n",
        "    print(f\"factorial({n}) = {value} [{source}]\")\n",
        "\n",
        "print(\"cache_info:\", factorial.cache_info())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7005ad",
      "metadata": {},
      "source": [
        "## Exercise 8: Caching System for API Data (real or simulated)\n",
        "\n",
        "- Build a function that \"queries\" an API (real or simulated).\n",
        "- Add caching with:\n",
        "  - key derived from request parameters;\n",
        "  - configurable expiration (TTL).\n",
        "- Include a small demo showing reduced number of API calls thanks to cache."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bcbd5032",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[api call] ('weather', (('city', 'Cluj'), ('unit', 'metric')))\n",
            "{'endpoint': 'weather', 'params': {'city': 'Cluj', 'unit': 'metric'}, 'payload': \"data_for_weather_{'city': 'Cluj', 'unit': 'metric'}\", 'call_number': 1}\n",
            "[cache hit] ('weather', (('city', 'Cluj'), ('unit', 'metric')))\n",
            "{'endpoint': 'weather', 'params': {'city': 'Cluj', 'unit': 'metric'}, 'payload': \"data_for_weather_{'city': 'Cluj', 'unit': 'metric'}\", 'call_number': 1}\n",
            "[api call] ('weather', (('city', 'Iasi'), ('unit', 'metric')))\n",
            "{'endpoint': 'weather', 'params': {'city': 'Iasi', 'unit': 'metric'}, 'payload': \"data_for_weather_{'city': 'Iasi', 'unit': 'metric'}\", 'call_number': 2}\n",
            "waiting for TTL expiration...\n",
            "[api call] ('weather', (('city', 'Cluj'), ('unit', 'metric')))\n",
            "{'endpoint': 'weather', 'params': {'city': 'Cluj', 'unit': 'metric'}, 'payload': \"data_for_weather_{'city': 'Cluj', 'unit': 'metric'}\", 'call_number': 3}\n",
            "Total API calls made: 3\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "api_cache = {}\n",
        "api_call_count = 0\n",
        "\n",
        "\n",
        "def fake_api(endpoint: str, **params):\n",
        "    global api_call_count\n",
        "    api_call_count += 1\n",
        "    time.sleep(0.25)  # simulate network latency\n",
        "    return {\n",
        "        \"endpoint\": endpoint,\n",
        "        \"params\": params,\n",
        "        \"payload\": f\"data_for_{endpoint}_{params}\",\n",
        "        \"call_number\": api_call_count,\n",
        "    }\n",
        "\n",
        "\n",
        "def get_api_data(endpoint: str, ttl: int = 3, **params):\n",
        "    key = (endpoint, tuple(sorted(params.items())))\n",
        "    now = time.time()\n",
        "\n",
        "    if key in api_cache:\n",
        "        data, expires_at = api_cache[key]\n",
        "        if now < expires_at:\n",
        "            print(\"[cache hit]\", key)\n",
        "            return data\n",
        "\n",
        "    print(\"[api call]\", key)\n",
        "    data = fake_api(endpoint, **params)\n",
        "    api_cache[key] = (data, now + ttl)\n",
        "    return data\n",
        "\n",
        "\n",
        "print(get_api_data(\"weather\", city=\"Cluj\", unit=\"metric\"))\n",
        "print(get_api_data(\"weather\", city=\"Cluj\", unit=\"metric\"))\n",
        "print(get_api_data(\"weather\", city=\"Iasi\", unit=\"metric\"))\n",
        "print(\"waiting for TTL expiration...\")\n",
        "time.sleep(3.2)\n",
        "print(get_api_data(\"weather\", city=\"Cluj\", unit=\"metric\"))\n",
        "print(\"Total API calls made:\", api_call_count)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da164d6",
      "metadata": {},
      "source": [
        "## Exercise 9: Execution Time Comparison - with and without cache\n",
        "\n",
        "- Choose a sufficiently expensive function (simulated with `sleep` or heavy computation).\n",
        "- Measure total time for a call set:\n",
        "  - once without cache;\n",
        "  - once with cache (manual / `lru_cache` / decorator).\n",
        "- Print results and conclusion (observed time difference)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7590a748",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "without cache: 1.321 seconds\n",
            "with cache   : 0.4806 seconds\n",
            "same outputs : True\n",
            "Speedup: 2.75x faster with cache\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "def slow_work_no_cache(x: int) -> int:\n",
        "    time.sleep(0.12)\n",
        "    return x * x\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=None)\n",
        "def slow_work_cached(x: int) -> int:\n",
        "    time.sleep(0.12)\n",
        "    return x * x\n",
        "\n",
        "\n",
        "inputs = [1, 2, 3, 2, 1, 3, 4, 1, 2, 4, 3]\n",
        "\n",
        "start = time.perf_counter()\n",
        "out_no_cache = [slow_work_no_cache(x) for x in inputs]\n",
        "time_no_cache = time.perf_counter() - start\n",
        "\n",
        "start = time.perf_counter()\n",
        "out_cached = [slow_work_cached(x) for x in inputs]\n",
        "time_cached = time.perf_counter() - start\n",
        "\n",
        "print(\"without cache:\", round(time_no_cache, 4), \"seconds\")\n",
        "print(\"with cache   :\", round(time_cached, 4), \"seconds\")\n",
        "print(\"same outputs :\", out_no_cache == out_cached)\n",
        "\n",
        "if time_cached < time_no_cache:\n",
        "    speedup = time_no_cache / time_cached if time_cached > 0 else float(\"inf\")\n",
        "    print(f\"Speedup: {speedup:.2f}x faster with cache\")\n",
        "else:\n",
        "    print(\"No speedup observed in this run\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
